# ğŸ„ Proyecto Final: ClasificaciÃ³n de Hongos

**Entrega final del proyecto para Modelos II**  
**Dataset:** UCI Mushroom Database  
**Objetivo:** Clasificar hongos como comestibles o venenosos usando 5 modelos de Machine Learning

---

## ğŸ“‹ DescripciÃ³n del Proyecto

ImplementaciÃ³n de **5 modelos de clasificaciÃ³n** siguiendo la metodologÃ­a del profesor con validaciÃ³n cruzada estratificada (StratifiedKFold):

1. âœ… **RegresiÃ³n LogÃ­stica** (ImplementaciÃ³n manual) - 94.58% accuracy
2. âœ… **K-Nearest Neighbors (KNN)** - 100% accuracy
3. âœ… **Random Forest** - 100% accuracy  
4. âœ… **Red Neuronal Artificial (MLP)** - 100% accuracy
5. â³ **Support Vector Machine (SVM)** - Pendiente

---

## ğŸ“Š Dataset

- **Fuente:** UCI Machine Learning Repository - Mushroom Database
- **Archivo:** `dataset_24_mushroom.arff`
- **Muestras:** 8,124 hongos
- **CaracterÃ­sticas:** 22 atributos categÃ³ricas (cap-shape, odor, gill-color, etc.)
- **Clases:** 
  - 0 = Comestible (edible)
  - 1 = Venenoso (poisonous)
- **DivisiÃ³n:** 70% entrenamiento, 30% prueba

---

## ğŸš€ Resultados Actuales

| Modelo | TÃ©cnica | Accuracy | ParÃ¡metros Ã“ptimos | ValidaciÃ³n |
|--------|---------|----------|-------------------|------------|
| 1 | RegresiÃ³n LogÃ­stica | 94.58% | Î·=10.0 | Manual |
| 2 | KNN | 100% | k=1 | StratifiedKFold (4 folds) |
| 3 | Random Forest | 100% | 50 trees, 5 vars | StratifiedKFold (4 folds) |
| 4 | MLP | 100% | (10,) - 1 capa, 10 neuronas | StratifiedKFold (4 folds) + K-fold robustness (3-20 folds) |
| 5 | SVM | Pendiente | - | - |

**Nota:** El dataset UCI Mushroom es perfectamente separable. Los resultados de 100% accuracy estÃ¡n validados y son correctos.

---

## ğŸ“ Estructura del Proyecto

```
Proyecto-final-clasificaciÃ³n de hongos/
â”‚
â”œâ”€â”€ Clasificacion_Hongos_5_Modelos.ipynb  # Notebook principal (51 celdas)
â”œâ”€â”€ dataset_24_mushroom.arff              # Dataset UCI
â”œâ”€â”€ README.md                             # Este archivo
â””â”€â”€ RESUMEN_PROGRESO.md                   # Resumen detallado para compartir
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.x**
- **LibrerÃ­as:**
  - NumPy (operaciones matemÃ¡ticas)
  - Pandas (manipulaciÃ³n de datos)
  - Matplotlib & Seaborn (visualizaciÃ³n)
  - scikit-learn (KNN, Random Forest, MLP, PCA, StandardScaler)
  - SciPy (lectura ARFF)

---

## ğŸ“ˆ MetodologÃ­a

### ImplementaciÃ³n siguiendo patrones del profesor:

1. **Funciones `experimentar_X()`** personalizadas para cada modelo
2. **StratifiedKFold(n_splits=4)** para validaciÃ³n cruzada
3. **DataFrames de resultados** con mÃ©tricas:
   - Error de entrenamiento (media)
   - DesviaciÃ³n estÃ¡ndar entrenamiento
   - Error de prueba (media)
   - Intervalo de confianza
4. **Visualizaciones 2D/3D con PCA** para cada modelo
5. **Matrices de confusiÃ³n** (entrenamiento y prueba)

---

## ğŸ¯ Hallazgos Principales

### Dataset Perfectamente Separable
- CaracterÃ­sticas altamente discriminativas: `odor`, `gill-color`, `spore-print-color`
- Modelos modernos alcanzan 100% accuracy naturalmente
- **ValidaciÃ³n robusta:** MLP validado con 53 entrenamientos adicionales (K-folds: 3, 5, 10, 15, 20)

### AnÃ¡lisis de Complejidad
- **Modelo mÃ¡s simple que alcanza 100%:** KNN con k=1
- **Red neuronal Ã³ptima:** 1 capa, 10 neuronas (convergencia en 113 iteraciones)
- **Random Forest Ã³ptimo:** 50 Ã¡rboles, 5 variables

### RegresiÃ³n LogÃ­stica
- **94.58% accuracy** - razonable para modelo lineal en problema no-lineal
- ImplementaciÃ³n manual completa (gradiente descendente, funciÃ³n de costo)
- Frontera de decisiÃ³n lineal visualizada

---

## ğŸ“Š Visualizaciones Incluidas

Cada modelo incluye:
- Matriz de confusiÃ³n (Train/Test)
- VisualizaciÃ³n 2D con PCA
- VisualizaciÃ³n 3D con PCA
- GrÃ¡ficas de mÃ©tricas especÃ­ficas

**Especiales:**
- **Modelo 1:** EvoluciÃ³n del costo
- **Modelo 3:** Importancia de caracterÃ­sticas
- **Modelo 4:** Heatmap comparativo, validaciÃ³n K-fold

---

## ğŸ”¬ PrÃ³ximos Pasos

- [ ] Implementar Modelo 5: Support Vector Machine (SVM)
- [ ] Tabla comparativa final de los 5 modelos
- [ ] AnÃ¡lisis de tiempo de entrenamiento
- [ ] Recomendaciones para deployment
- [ ] Conclusiones finales del proyecto

---

## ğŸ“ Notas del Desarrollo

### Â¿Por quÃ© 100% accuracy es vÃ¡lido?
- Dataset UCI Mushroom documentado como perfectamente separable
- ValidaciÃ³n exhaustiva con mÃºltiples configuraciones de K-fold
- Gap Train-Test = 0% (no hay sobreajuste)
- Confusion matrices perfectas: sin falsos positivos/negativos

### Validaciones realizadas:
âœ… StratifiedKFold con 4 folds en todos los modelos  
âœ… ValidaciÃ³n adicional MLP: 3, 5, 10, 15, 20 folds (53 entrenamientos)  
âœ… MÃ©tricas perfectas: Precision=100%, Recall=100%, F1=100%  
âœ… PCA 2D/3D confirma separabilidad visual  

---

## ğŸ‘¨â€ğŸ’» Autor

**Camilo**  
Curso: Modelos II  
Fecha: Noviembre 2025

---

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad

---

**Ãšltima actualizaciÃ³n:** 20 de Noviembre de 2025  
**Estado:** 4/5 modelos completados âœ…  
**Notebook ejecutado:** âœ… Todas las celdas funcionando
